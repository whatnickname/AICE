{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac05243-df0c-4216-8a72-b261e6b8cc6d",
   "metadata": {},
   "source": [
    "# <B> 1.머신러닝 모델 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24e09f-4e3e-4efa-af81-6c49d73653c8",
   "metadata": {},
   "source": [
    "## <B> (1) 회귀모델튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96a3fa-e11c-4c56-b122-b22fab419aff",
   "metadata": {},
   "source": [
    "### <B> ○ 선형회귀 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392aa8ea-43e3-4109-8244-a553e57b20b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE: 50508878.30765215\n",
      "Lasso Regression MSE: 50508855.78114255\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('datasets/Clean_Dataset.csv')\n",
    "df = df.drop(['flight', 'departure_time', 'stops', 'arrival_time'], axis=1) # 학습에 필요 없는 문자열 열 제거\n",
    "df = pd.get_dummies(df, columns=['airline', 'source_city', 'destination_city', 'class'], drop_first=True)\n",
    "X = df.drop('price', axis=1)  # 독립 변수\n",
    "y = df['price']  # 종속 변수\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ridge Regression (L2 정규화)\n",
    "ridge = Ridge(alpha=1.0)  # L2 정규화 강도\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_preds = ridge.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_preds)\n",
    "\n",
    "# Lasso Regression (L1 정규화)\n",
    "lasso = Lasso(alpha=0.1)  # L1 정규화 강도\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_preds = lasso.predict(X_test)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_preds)\n",
    "\n",
    "print(\"Ridge Regression MSE:\", ridge_mse)\n",
    "print(\"Lasso Regression MSE:\", lasso_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76992460-6715-4ad3-949b-4fcc65a77e0e",
   "metadata": {},
   "source": [
    "### <B> ○ 랜덤 포레스트 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a14921-17fe-40f0-8b9f-5538f2afe1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 20024154.727510292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('datasets/Clean_Dataset.csv')\n",
    "df = df.drop(['flight', 'departure_time', 'stops', 'arrival_time'], axis=1) # 학습에 필요 없는 문자열 열 제거\n",
    "df = pd.get_dummies(df, columns=['airline', 'source_city', 'destination_city', 'class'], drop_first=True)\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 모델\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,      # 트리 개수 (100개의 트리)\n",
    "    max_depth=10,          # 각 트리의 최대 깊이\n",
    "    min_samples_split=5,   # 노드를 분할하기 위한 최소 샘플 수\n",
    "    min_samples_leaf=2,    # 리프 노드에 있어야 하는 최소 샘플 수\n",
    "    random_state=42        # 결과 재현성을 위한 설정\n",
    ")\n",
    "rf.fit(X_train, y_train)  # 모델 학습\n",
    "rf_preds = rf.predict(X_test)  # 테스트 데이터 예측\n",
    "rf_mse = mean_squared_error(y_test, rf_preds)  # MSE 계산\n",
    "\n",
    "print(\"Random Forest MSE:\", rf_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1481d17-8740-401e-badc-65390066e483",
   "metadata": {},
   "source": [
    "### <B> ○ 그래디언 부스트 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb73067-ef74-4d1b-95d2-55a0801ba551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting MSE: 20996731.384828538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('datasets/Clean_Dataset.csv')\n",
    "df = df.drop(['flight', 'departure_time', 'stops', 'arrival_time'], axis=1) # 학습에 필요 없는 문자열 열 제거\n",
    "df = pd.get_dummies(df, columns=['airline', 'source_city', 'destination_city', 'class'], drop_first=True)\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 그래디언트 부스트 모델\n",
    "gb = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,     # 학습률\n",
    "    n_estimators=100,      # 트리 개수\n",
    "    max_depth=5,           # 각 트리의 최대 깊이\n",
    "    random_state=42        # 결과 재현성을 위한 설정\n",
    ")\n",
    "gb.fit(X_train, y_train)  # 모델 학습\n",
    "gb_preds = gb.predict(X_test)  # 테스트 데이터 예측\n",
    "gb_mse = mean_squared_error(y_test, gb_preds)  # MSE 계산\n",
    "\n",
    "print(\"Gradient Boosting MSE:\", gb_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55773b40-3ada-4fbb-aca8-e3e24e744637",
   "metadata": {},
   "source": [
    "## <B> (2) 분류모델튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92f3b5-afdb-4165-88cd-feba917cc583",
   "metadata": {},
   "source": [
    "### <B> ○ 의사결정나무모델 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ef95f78-c379-49e0-bac5-641cf3dde6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.8524590163934426\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86        29\n",
      "           1       0.96      0.75      0.84        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.87      0.86      0.85        61\n",
      "weighted avg       0.87      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('datasets/heart.csv')\n",
    "X = df.drop('output', axis=1)  # 독립 변수\n",
    "y = df['output']              # 종속 변수 (심장병 여부: 1=있음, 0=없음)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 의사결정 나무 모델\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=5,          # 트리의 최대 깊이\n",
    "    min_samples_split=10, # 노드를 분할하기 위한 최소 샘플 수\n",
    "    min_samples_leaf=5,   # 리프 노드에 있어야 하는 최소 샘플 수\n",
    "    random_state=42       # 결과 재현성을 위한 설정\n",
    ")\n",
    "dt.fit(X_train, y_train)  # 모델 학습\n",
    "\n",
    "# 모델 평가\n",
    "dt_preds = dt.predict(X_test)  # 테스트 데이터 예측\n",
    "accuracy = accuracy_score(y_test, dt_preds)  # 정확도 계산\n",
    "print(\"Decision Tree Classifier Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, dt_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b58f5d-ecf4-4feb-a834-fa07466ff41f",
   "metadata": {},
   "source": [
    "### <B> ○ 로지스틱 회귀 모델 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e153845-8e3f-40cf-83f6-05fee7f84db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8688524590163934\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        29\n",
      "           1       0.88      0.88      0.88        32\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('datasets/heart.csv')\n",
    "X = df.drop('output', axis=1)\n",
    "y = df['output']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 로지스틱 회귀 모델\n",
    "log_reg = LogisticRegression(\n",
    "    C=1.0,           # 정규화 강도\n",
    "    penalty='l2',    # L2 정규화\n",
    "    solver='liblinear'  # 소규모 데이터셋에 적합한 솔버\n",
    ")\n",
    "log_reg.fit(X_train, y_train)  # 모델 학습\n",
    "\n",
    "# 모델 평가\n",
    "log_preds = log_reg.predict(X_test)  # 테스트 데이터 예측\n",
    "accuracy = accuracy_score(y_test, log_preds)  # 정확도 계산\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, log_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e23d07-c90b-48b2-8475-da4cbedfd530",
   "metadata": {},
   "source": [
    "### <B> ○ 랜덤 포레스트 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b07cf2fd-2f92-4ebe-983b-0497a61739c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.8360655737704918\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        29\n",
      "           1       0.84      0.84      0.84        32\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.84      0.84      0.84        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('datasets/heart.csv')\n",
    "X = df.drop('output', axis=1)\n",
    "y = df['output']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 분류 모델\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,      # 트리 개수\n",
    "    max_depth=10,          # 트리의 최대 깊이\n",
    "    min_samples_split=5,   # 노드를 분할하기 위한 최소 샘플 수\n",
    "    min_samples_leaf=3,    # 리프 노드에 있어야 하는 최소 샘플 수\n",
    "    random_state=42        # 결과 재현성을 위한 설정\n",
    ")\n",
    "rf.fit(X_train, y_train)  # 모델 학습\n",
    "\n",
    "# 모델 평가\n",
    "rf_preds = rf.predict(X_test)  # 테스트 데이터 예측\n",
    "accuracy = accuracy_score(y_test, rf_preds)  # 정확도 계산\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b385f970-2cd8-4381-b682-184164860786",
   "metadata": {},
   "source": [
    "### <B> ○ 그래디언트 부스트 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "802100ba-b2dd-4be7-9eca-7c024f279974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.819672131147541\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        29\n",
      "           1       0.84      0.84      0.84        32\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.84      0.84      0.84        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('datasets/heart.csv')\n",
    "X = df.drop('output', axis=1)\n",
    "y = df['output']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 그래디언트 부스트 분류 모델\n",
    "gb = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,     # 학습률\n",
    "    n_estimators=100,      # 부스팅 반복 횟수 (트리 개수)\n",
    "    max_depth=5,           # 각 트리의 최대 깊이\n",
    "    min_samples_split=10,  # 노드를 분할하기 위한 최소 샘플 수\n",
    "    min_samples_leaf=5,    # 리프 노드에 있어야 하는 최소 샘플 수\n",
    "    random_state=42        # 결과 재현성을 위한 설정\n",
    ")\n",
    "gb.fit(X_train, y_train)  # 모델 학습\n",
    "\n",
    "# 모델 평가\n",
    "gb_preds = gb.predict(X_test)  # 테스트 데이터 예측\n",
    "accuracy = accuracy_score(y_test, gb_preds)  # 정확도 계산\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037e4db-9a62-47fe-ae55-f7296687f668",
   "metadata": {},
   "source": [
    "### <B> ○ SVM 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24fb172d-c745-41c1-aa19-a7e06b73c329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 0.7049180327868853\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.52      0.62        29\n",
      "           1       0.67      0.88      0.76        32\n",
      "\n",
      "    accuracy                           0.70        61\n",
      "   macro avg       0.73      0.70      0.69        61\n",
      "weighted avg       0.73      0.70      0.69        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('datasets/heart.csv')  # heart.csv 파일 로드\n",
    "X = df.drop('output', axis=1)  # 독립 변수 (특징 데이터)\n",
    "y = df['output']               # 종속 변수 (1: 심장병 있음, 0: 없음)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM 분류 모델 설정\n",
    "svm = SVC(\n",
    "    kernel='rbf',    # RBF 커널 (비선형 데이터 처리)\n",
    "    C=1.0,           # 정규화 강도\n",
    "    gamma='scale'    # 감마 설정 (특성 스케일에 따라 자동 설정)\n",
    ")\n",
    "svm.fit(X_train, y_train)  # 모델 학습\n",
    "\n",
    "# 모델 평가\n",
    "svm_preds = svm.predict(X_test)  # 테스트 데이터 예측\n",
    "accuracy = accuracy_score(y_test, svm_preds)  # 정확도 계산\n",
    "print(\"SVM Classifier Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, svm_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0917f-9bbd-493b-82a1-aae1e46bb3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e18ab6-7bbd-4e2c-9f21-4712cac7ab16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
