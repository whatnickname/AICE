{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9581b82-6df5-4be2-8f56-9d31e422e12f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 텐서플로 설치 및 기본 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d20c4ae-e1ac-4e63-9f2d-e7d82a8a3cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.18.0\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow==2.18.0)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.71.0)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow==2.18.0)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow==2.18.0)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\media-cam2\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/390.3 MB 5.9 MB/s eta 0:01:06\n",
      "   ---------------------------------------- 0.7/390.3 MB 8.4 MB/s eta 0:00:47\n",
      "   ---------------------------------------- 1.4/390.3 MB 10.7 MB/s eta 0:00:37\n",
      "   ---------------------------------------- 2.3/390.3 MB 12.0 MB/s eta 0:00:33\n",
      "   ---------------------------------------- 3.5/390.3 MB 15.7 MB/s eta 0:00:25\n",
      "    --------------------------------------- 5.1/390.3 MB 19.1 MB/s eta 0:00:21\n",
      "    --------------------------------------- 7.4/390.3 MB 23.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 10.7/390.3 MB 34.6 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 13.7/390.3 MB 54.7 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 16.6/390.3 MB 65.6 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 19.5/390.3 MB 65.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 22.3/390.3 MB 65.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 24.5/390.3 MB 59.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 26.2/390.3 MB 54.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 28.7/390.3 MB 50.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 31.9/390.3 MB 54.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 34.8/390.3 MB 59.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 36.9/390.3 MB 59.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 37.4/390.3 MB 50.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 38.6/390.3 MB 43.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 40.0/390.3 MB 38.5 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 41.6/390.3 MB 36.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 42.1/390.3 MB 32.7 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 42.3/390.3 MB 27.3 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 42.5/390.3 MB 25.2 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 42.9/390.3 MB 22.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 44.5/390.3 MB 21.1 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 46.1/390.3 MB 20.5 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 47.8/390.3 MB 22.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 49.6/390.3 MB 23.4 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 51.4/390.3 MB 23.4 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 53.2/390.3 MB 36.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 55.1/390.3 MB 38.6 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 56.9/390.3 MB 38.6 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 58.7/390.3 MB 38.5 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 60.7/390.3 MB 38.5 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 62.6/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 63.1/390.3 MB 38.6 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 63.2/390.3 MB 32.7 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 63.3/390.3 MB 28.4 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 63.4/390.3 MB 25.1 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 63.6/390.3 MB 21.8 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 63.9/390.3 MB 20.5 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 65.3/390.3 MB 19.8 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 67.1/390.3 MB 19.8 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 68.8/390.3 MB 19.8 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 71.0/390.3 MB 19.8 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 73.0/390.3 MB 19.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 75.0/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 75.7/390.3 MB 38.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 75.8/390.3 MB 32.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 76.1/390.3 MB 28.5 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 76.9/390.3 MB 26.2 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 79.2/390.3 MB 28.4 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 81.4/390.3 MB 27.3 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 83.9/390.3 MB 28.5 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 86.0/390.3 MB 36.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 88.4/390.3 MB 50.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 90.7/390.3 MB 50.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 93.1/390.3 MB 50.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 94.4/390.3 MB 50.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 94.4/390.3 MB 50.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 94.4/390.3 MB 50.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 94.4/390.3 MB 50.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 96.3/390.3 MB 27.3 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 98.3/390.3 MB 26.2 MB/s eta 0:00:12\n",
      "   --------- ----------------------------- 100.0/390.3 MB 26.2 MB/s eta 0:00:12\n",
      "   ---------- ---------------------------- 101.8/390.3 MB 25.2 MB/s eta 0:00:12\n",
      "   ---------- ---------------------------- 103.5/390.3 MB 24.2 MB/s eta 0:00:12\n",
      "   ---------- ---------------------------- 105.4/390.3 MB 38.5 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 107.3/390.3 MB 38.5 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 109.2/390.3 MB 38.6 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 111.1/390.3 MB 38.6 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 113.0/390.3 MB 38.6 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 114.8/390.3 MB 38.5 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 116.7/390.3 MB 38.5 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 118.8/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 120.9/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 123.1/390.3 MB 43.5 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 125.4/390.3 MB 43.7 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 127.6/390.3 MB 46.9 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 130.0/390.3 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 132.3/390.3 MB 50.4 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 134.6/390.3 MB 50.4 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 137.0/390.3 MB 50.4 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 139.3/390.3 MB 50.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 141.6/390.3 MB 50.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 143.0/390.3 MB 43.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 143.6/390.3 MB 38.6 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 145.9/390.3 MB 38.6 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 148.3/390.3 MB 38.5 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 150.5/390.3 MB 38.5 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 153.3/390.3 MB 43.5 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 156.1/390.3 MB 54.4 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 158.8/390.3 MB 54.4 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 161.5/390.3 MB 59.8 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 164.3/390.3 MB 59.5 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 166.9/390.3 MB 59.5 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 169.8/390.3 MB 65.6 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 172.6/390.3 MB 65.6 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 175.5/390.3 MB 65.6 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 178.3/390.3 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 181.3/390.3 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 184.1/390.3 MB 59.8 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 187.0/390.3 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 190.2/390.3 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 192.8/390.3 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 195.1/390.3 MB 54.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 197.4/390.3 MB 54.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 199.8/390.3 MB 50.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 202.0/390.3 MB 46.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 204.3/390.3 MB 46.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 206.6/390.3 MB 46.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 209.1/390.3 MB 50.4 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 211.4/390.3 MB 50.4 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 213.7/390.3 MB 46.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 215.9/390.3 MB 46.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 218.2/390.3 MB 46.7 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 220.5/390.3 MB 50.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 223.0/390.3 MB 50.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 225.9/390.3 MB 50.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 228.6/390.3 MB 54.7 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 231.3/390.3 MB 54.7 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 234.0/390.3 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 236.8/390.3 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 239.6/390.3 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 242.4/390.3 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 245.3/390.3 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 248.0/390.3 MB 65.2 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 250.7/390.3 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 253.5/390.3 MB 59.8 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 255.4/390.3 MB 54.7 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 256.8/390.3 MB 50.4 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 258.1/390.3 MB 43.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 259.5/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 260.9/390.3 MB 36.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 262.5/390.3 MB 34.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 264.0/390.3 MB 32.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 265.6/390.3 MB 32.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 267.2/390.3 MB 32.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 269.0/390.3 MB 34.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 270.9/390.3 MB 36.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 272.6/390.3 MB 36.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 274.4/390.3 MB 38.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 276.1/390.3 MB 38.5 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 278.0/390.3 MB 38.5 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 279.8/390.3 MB 38.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 281.6/390.3 MB 38.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 283.4/390.3 MB 38.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 285.3/390.3 MB 38.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 287.1/390.3 MB 38.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 289.0/390.3 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 290.9/390.3 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 292.9/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 295.1/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 297.4/390.3 MB 43.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 299.7/390.3 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 302.1/390.3 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 302.2/390.3 MB 43.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 302.3/390.3 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 302.6/390.3 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 304.2/390.3 MB 28.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 306.2/390.3 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 306.2/390.3 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 306.2/390.3 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 306.2/390.3 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 307.2/390.3 MB 19.3 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 309.5/390.3 MB 19.3 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 311.8/390.3 MB 19.2 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 314.1/390.3 MB 26.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 316.5/390.3 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 318.0/390.3 MB 46.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 319.2/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 320.3/390.3 MB 38.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 321.7/390.3 MB 34.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 323.0/390.3 MB 32.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 324.4/390.3 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 325.8/390.3 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 327.2/390.3 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 328.7/390.3 MB 28.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 330.1/390.3 MB 29.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 331.6/390.3 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 333.1/390.3 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 334.7/390.3 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 336.3/390.3 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 337.9/390.3 MB 31.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 339.6/390.3 MB 34.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 341.4/390.3 MB 36.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 343.2/390.3 MB 36.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 344.9/390.3 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 346.7/390.3 MB 38.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 348.6/390.3 MB 38.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 350.5/390.3 MB 38.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 352.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 354.1/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 355.9/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 357.8/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 359.7/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 361.7/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 363.9/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 366.2/390.3 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 368.6/390.3 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 370.9/390.3 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 373.2/390.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 375.5/390.3 MB 50.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 377.7/390.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 380.1/390.3 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.9/390.3 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.3/390.3 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  386.4/390.3 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  388.0/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.0/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.3/390.3 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.5/127.5 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 64.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 64.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 64.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.5 MB 64.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 11.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 18.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 17.6 MB/s eta 0:00:00\n",
      "Installing collected packages: ml-dtypes, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml_dtypes 0.5.1\n",
      "    Uninstalling ml_dtypes-0.5.1:\n",
      "      Successfully uninstalled ml_dtypes-0.5.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.19.0\n",
      "    Uninstalling tensorboard-2.19.0:\n",
      "      Successfully uninstalled tensorboard-2.19.0\n",
      "Successfully installed ml-dtypes-0.4.1 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-intel-2.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-cpu 2.19.0 requires ml-dtypes<1.0.0,>=0.5.1, but you have ml-dtypes 0.4.1 which is incompatible.\n",
      "tensorflow-cpu 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.18.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 설치\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09de9cf4-811d-40dc-8400-327e3f1588fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "# 작동 확인 및 버전 확인\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051e956-a4a2-4ae2-8af4-b54adf7e3c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46678465-ffd6-4833-8d89-f1a1fcc32e1f",
   "metadata": {},
   "source": [
    "## 텐서플로 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72734277-42cb-4a83-9f7b-956caaf19b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 데이터 :  [[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]]\n",
      "x shape :  (10, 1)\n",
      "y 데이터 :  [[ 8]\n",
      " [11]\n",
      " [14]\n",
      " [17]\n",
      " [20]\n",
      " [23]\n",
      " [26]\n",
      " [29]\n",
      " [32]\n",
      " [35]]\n",
      "y shape :  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 불러오기\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Numpy를 이용하여 학습데이터 생성하기\n",
    "# 학습 데이터 정의\n",
    "x = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
    "\n",
    "y = np.array([[8], [11], [14], [17], [20], [23], [26], [29], [32], [35]])\n",
    "\n",
    "\n",
    "print('x 데이터 : ', x)\n",
    "print('x shape : ', x.shape)\n",
    "print('y 데이터 : ', y)\n",
    "print('y shape : ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db4a215f-e88e-413c-84ef-5b52235f6183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m2\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sequential 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "# Dense 층 추가\n",
    "model.add(Dense(\n",
    "    units=1,                       # 출력 뉴런의 수\n",
    "    activation='linear',           # 활성화 함수\n",
    "    input_shape=[1],               # 입력 데이터의 형태\n",
    "    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=55),  # GlorotUniform 초기화\n",
    "))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "480c1706-b9b9-4afd-993d-1121b3fa3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer='sgd',                # 옵티마이저: SGD\n",
    "    loss='mean_squared_error',       # 손실 함수: 평균 제곱 오차\n",
    "    metrics=['mae']                  # 추가 메트릭: 평균 절대 오차\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6012bc97-eff8-494e-8f6f-6fb9687b7c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807ms/step - loss: 553.1721 - mae: 21.8181\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 29.4275 - mae: 5.4068\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 5.3634 - mae: 1.9308\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.2257 - mae: 1.7073\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4.1401 - mae: 1.6957\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 4.1031 - mae: 1.6900\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4.0686 - mae: 1.6846\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4.0345 - mae: 1.6779\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4.0007 - mae: 1.6709\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 3.9672 - mae: 1.6639\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 3.9339 - mae: 1.6569\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 3.9009 - mae: 1.6500\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 3.8682 - mae: 1.6430\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 3.8358 - mae: 1.6361\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 3.8037 - mae: 1.6293\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.7718 - mae: 1.6224\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 3.7402 - mae: 1.6156\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.7088 - mae: 1.6088\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3.6777 - mae: 1.6021\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 3.6469 - mae: 1.5953\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 3.6164 - mae: 1.5886\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 3.5860 - mae: 1.5820\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 3.5560 - mae: 1.5753\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3.5262 - mae: 1.5687\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 3.4966 - mae: 1.5621\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 3.4673 - mae: 1.5556\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 3.4383 - mae: 1.5490\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 3.4094 - mae: 1.5425\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3.3809 - mae: 1.5360\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 3.3525 - mae: 1.5296\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3.3244 - mae: 1.5232\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 3.2966 - mae: 1.5168\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 3.2689 - mae: 1.5104\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 3.2415 - mae: 1.5041\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3.2144 - mae: 1.4977\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.1874 - mae: 1.4915\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 3.1607 - mae: 1.4852\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.1342 - mae: 1.4790\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 3.1080 - mae: 1.4727\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3.0819 - mae: 1.4666\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 3.0561 - mae: 1.4604\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 3.0305 - mae: 1.4543\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 3.0051 - mae: 1.4482\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2.9799 - mae: 1.4421\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.9549 - mae: 1.4360\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 2.9301 - mae: 1.4300\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2.9056 - mae: 1.4240\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 2.8812 - mae: 1.4180\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 2.8571 - mae: 1.4121\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 2.8331 - mae: 1.4061\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 2.8094 - mae: 1.4002\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2.7858 - mae: 1.3943\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 2.7625 - mae: 1.3885\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.7393 - mae: 1.3827\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 2.7164 - mae: 1.3768\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 2.6936 - mae: 1.3711\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 2.6710 - mae: 1.3653\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 2.6486 - mae: 1.3596\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.6264 - mae: 1.3539\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 2.6044 - mae: 1.3482\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.5826 - mae: 1.3425\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2.5610 - mae: 1.3369\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.5395 - mae: 1.3313\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 2.5182 - mae: 1.3257\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2.4971 - mae: 1.3201\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 2.4762 - mae: 1.3146\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 2.4554 - mae: 1.3090\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 2.4348 - mae: 1.3035\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 2.4144 - mae: 1.2981\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.3942 - mae: 1.2926\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 2.3741 - mae: 1.2872\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 2.3542 - mae: 1.2818\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2.3345 - mae: 1.2764\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.3149 - mae: 1.2710\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 2.2955 - mae: 1.2657\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2.2763 - mae: 1.2604\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 2.2572 - mae: 1.2551\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 2.2383 - mae: 1.2498\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 2.2195 - mae: 1.2446\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 2.2009 - mae: 1.2393\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 2.1825 - mae: 1.2341\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 2.1642 - mae: 1.2290\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 2.1460 - mae: 1.2238\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.1281 - mae: 1.2187\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 2.1102 - mae: 1.2135\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 2.0925 - mae: 1.2084\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 2.0750 - mae: 1.2034\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 2.0576 - mae: 1.1983\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 2.0404 - mae: 1.1933\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 2.0233 - mae: 1.1883\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 2.0063 - mae: 1.1833\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 1.9895 - mae: 1.1783\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.9728 - mae: 1.1734\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.9563 - mae: 1.1684\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 1.9399 - mae: 1.1635\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.9236 - mae: 1.1586\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 1.9075 - mae: 1.1538\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 1.8915 - mae: 1.1489\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 1.8757 - mae: 1.1441\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 1.8599 - mae: 1.1393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e9caab2390>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(\n",
    "    x,                      # 입력 데이터\n",
    "    y,                      # 출력 데이터 (레이블)\n",
    "    epochs=100              # 학습 반복 횟수 (Epochs)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17766fb5-3425-4f97-b2d7-f01d514ad5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=sequential_2/dense_2/kernel, shape=(1, 1), dtype=float32, value=[[3.421384]]>,\n",
       " <Variable path=sequential_2/dense_2/bias, shape=(1,), dtype=float32, value=[2.0663993]>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 모델 가중치 확인\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "787092ce-5475-4195-8138-992fab0d0ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치: [[3.421384]]\n",
      "바이어스: [2.0663993]\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 레이어의 가중치와 바이어스 출력\n",
    "weights, biases = model.layers[0].get_weights()\n",
    "print(f\"가중치: {weights}\")\n",
    "print(f\"바이어스: {biases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da223c2d-6501-4068-a4eb-0402eba5adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "[[43.12301 ]\n",
      " [49.965775]\n",
      " [56.808544]\n",
      " [63.651314]\n",
      " [70.49408 ]]\n"
     ]
    }
   ],
   "source": [
    "# 예측할 데이터 numpy를 이용하여 생성\n",
    "new_data = np.array([[12], [14], [16], [18], [20]])\n",
    "\n",
    "# 예측\n",
    "predictions = model.predict(new_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "723851f0-a854-444a-aea3-83c2a2ccb809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module keras.src.backend.tensorflow.trainer:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1) method of keras.src.models.sequential.Sequential instance\n",
      "    Trains the model for a fixed number of epochs (dataset iterations).\n",
      "\n",
      "    Args:\n",
      "        x: Input data. It can be:\n",
      "            - A NumPy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "            - A backend-native tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "            - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "            - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "            - A `tf.data.Dataset` yielding `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "            - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n",
      "            or `(inputs, targets, sample_weights)`.\n",
      "            - A Python generator function yielding `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "        y: Target data. Like the input data `x`, it can be either NumPy\n",
      "            array(s) or backend-native tensor(s). If `x` is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or a Python generator function,\n",
      "            `y` should not be specified since targets will be obtained from\n",
      "            `x`.\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your input data `x` is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function\n",
      "            since they generate batches.\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided\n",
      "            (unless the `steps_per_epoch` flag is set to\n",
      "            something other than None).\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "            \"auto\" becomes 1 for most cases.\n",
      "            Note that the progress bar is not\n",
      "            particularly useful when logged to a file,\n",
      "            so `verbose=2` is recommended when not running interactively\n",
      "            (e.g., in a production environment). Defaults to `\"auto\"`.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training.\n",
      "            See `keras.callbacks`. Note\n",
      "            `keras.callbacks.ProgbarLogger` and\n",
      "            `keras.callbacks.History` callbacks are created\n",
      "            automatically and need not be passed to `model.fit()`.\n",
      "            `keras.callbacks.ProgbarLogger` is created\n",
      "            or not based on the `verbose` argument in `model.fit()`.\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate the loss and any model\n",
      "            metrics on this data at the end of each epoch. The validation\n",
      "            data is selected from the last samples in the `x` and `y` data\n",
      "            provided, before shuffling.\n",
      "            This argument is only supported when `x` and `y` are made of\n",
      "            NumPy arrays or tensors.\n",
      "            If both `validation_data` and `validation_split` are provided,\n",
      "            `validation_data` will override `validation_split`.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data. Thus, note the fact\n",
      "            that the validation loss of data provided using\n",
      "            `validation_split` or `validation_data` is not affected by\n",
      "            regularization layers like noise and dropout.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            It can be:\n",
      "            - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
      "            - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
      "            arrays.\n",
      "            - A `keras.utils.PyDataset`, a `tf.data.Dataset`, a\n",
      "            `torch.utils.data.DataLoader` yielding `(inputs, targets)` or a\n",
      "            Python generator function yielding `(x_val, y_val)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "        shuffle: Boolean, whether to shuffle the training data before each\n",
      "            epoch. This argument is ignored when `x` is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class. When `class_weight` is specified\n",
      "            and targets have a rank of 2 or greater, either `y` must be\n",
      "            one-hot encoded, or an explicit final dimension of `1` must\n",
      "            be included for sparse class labels.\n",
      "        sample_weight: Optional NumPy array or tensor of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            NumPy array or tensor with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples), or in the case of\n",
      "            temporal data, you can pass a 2D NumPy array or tensor with\n",
      "            shape `(samples, sequence_length)` to apply a different weight\n",
      "            to every timestep of every sample.\n",
      "            This argument is not supported when `x` is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function.\n",
      "            Instead, provide `sample_weights` as the third element of `x`.\n",
      "            Note that sample weighting does not apply to metrics specified\n",
      "            via the `metrics` argument in `compile()`. To apply sample\n",
      "            weighting to your metrics, you can specify them via the\n",
      "            `weighted_metrics` in `compile()` instead.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples) before declaring one\n",
      "            epoch finished and starting the next epoch. When training with\n",
      "            input tensors or NumPy arrays, the default `None` means that the\n",
      "            value used is the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined.\n",
      "            If `x` is a `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function, the\n",
      "            epoch will run until the input dataset is exhausted. When\n",
      "            passing an infinitely repeating dataset, you must specify the\n",
      "            `steps_per_epoch` argument, otherwise the training will run\n",
      "            indefinitely.\n",
      "        validation_steps: Integer or `None`.\n",
      "            Only relevant if `validation_data` is provided.\n",
      "            Total number of steps (batches of samples) to draw before\n",
      "            stopping when performing validation at the end of every epoch.\n",
      "            If `validation_steps` is `None`, validation will run until the\n",
      "            `validation_data` dataset is exhausted. In the case of an\n",
      "            infinitely repeating dataset, it will run indefinitely. If\n",
      "            `validation_steps` is specified and only part of the dataset\n",
      "            is consumed, the evaluation will start from the beginning of the\n",
      "            dataset at each epoch. This ensures that the same validation\n",
      "            samples are used every time.\n",
      "        validation_batch_size: Integer or `None`.\n",
      "            Number of samples per validation batch.\n",
      "            If unspecified, will default to `batch_size`.\n",
      "            Do not specify the `validation_batch_size` if your data is a\n",
      "            `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "            `torch.utils.data.DataLoader` or Python generator function\n",
      "            since they generate batches.\n",
      "        validation_freq: Only relevant if validation data is provided.\n",
      "            Specifies how many training epochs to run\n",
      "            before a new validation run is performed,\n",
      "            e.g. `validation_freq=2` runs validation every 2 epochs.\n",
      "\n",
      "    Unpacking behavior for iterator-like inputs:\n",
      "        A common pattern is to pass an iterator like object such as a\n",
      "        `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
      "        which will in fact yield not only features (`x`)\n",
      "        but optionally targets (`y`) and sample weights (`sample_weight`).\n",
      "        Keras requires that the output of such iterator-likes be\n",
      "        unambiguous. The iterator should return a tuple\n",
      "        of length 1, 2, or 3, where the optional second and third elements\n",
      "        will be used for `y` and `sample_weight` respectively.\n",
      "        Any other type provided will be wrapped in\n",
      "        a length-one tuple, effectively treating everything as `x`. When\n",
      "        yielding dicts, they should still adhere to the top-level tuple\n",
      "        structure,\n",
      "        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      "        features, targets, and weights from the keys of a single dict.\n",
      "        A notable unsupported data type is the `namedtuple`. The reason is\n",
      "        that it behaves like both an ordered datatype (tuple) and a mapping\n",
      "        datatype (dict). So given a namedtuple of the form:\n",
      "        `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      "        it is ambiguous whether to reverse the order of the elements when\n",
      "        interpreting the value. Even worse is a tuple of the form:\n",
      "        `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      "        where it is unclear if the tuple was intended to be unpacked\n",
      "        into `x`, `y`, and `sample_weight` or passed through\n",
      "        as a single element to `x`.\n",
      "\n",
      "    Returns:\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사용법 확인\n",
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901791a-93a3-4edb-be55-c24cd1beef4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
